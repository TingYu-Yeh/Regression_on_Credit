---
title: "HW5 - Practice for Regression Modeling"
author: "Ting-Yu Yeh"
date: "11 June 2021"
output: html_document
---
### Data Preprocessing and Summary
#### Import dataset - Credit
I choose dataset "Credit" from ISLR to practice regression modeling. 
```{r}
library(ISLR)
```

```{r}
# Basic data summary
indata <- Credit
summary(indata)
```

#### Split Data into Training Set and Testing Set
```{r}
train_index = sample(1:nrow(indata), 0.8*nrow(indata)) 
train = indata[train_index,]
test  = indata[-train_index,]
```
```{r}
# Training and testing set summary
summary(train)
summary(test)
```

#### Exploratory Data Analysis
```{r}
# Continuous exploratory variables analysis
round(cor(train[,c(2:7,12)]),digit=3)
round(cor(test[,c(2:7,12)]),digit=3)
```

```{r}
# Dealing with categorical dummy variables
full <- lm(Balance~ ., data = train[,-1])
XX <- model.matrix(full)
train2 <- data.frame(XX[,-1],Balance=train$Balance)

fullT <- lm(Balance~., data = test[,-1])
XXT <- model.matrix(fullT)
test2 <- data.frame(XXT[,-1],Balance=test$Balance)
```

```{r}
# Scatter Matrix Plot for training data
pairs(train2, col=4, pch=16)
```

```{r}
# Correlation matrix of each two variables including categorical dummy variables
round(cor(train2),digit=3)
```
* We could find that "Limit" and "Rating" have the highest correlation values (0.863 and 0.866 respectively) regarding to "Balance".
* Therefore, I choose "Limit" and "Rating" variables to do simple linear regression.
### Simple linear regression
* Estimate coefficients by **least squares method**.

#### "Rating" variables
```{r}
# Building the fitting line of "Rating" and "Balance"
fit1.1 <- lm(Balance~Rating, data= train2)
```

```{r}
summary(fit1.1)
```

```{r}
# ANOVA analysis
anova(fit1.1)
```

```{r}
# The estimated values of the coefficients
coefficients(fit1.1)
```

```{r}
# The confience interval
confint(fit1.1,level = 0.95)
```

```{r}
# Plotting with Estimated Values
plot(Balance~Rating, data= train2, pch = 16)
abline(fit1.1,col=4,lwd=2)
X_plot <- data.frame(Rating=seq(0,2000,by=1))
fit1.1_pred <- predict(fit1.1, newdata = X_plot, interval = "confidence")
lines(X_plot$Rating,fit1.1_pred[,2],col=5, lwd=2)
lines(X_plot$Rating,fit1.1_pred[,3],col=5, lwd=2)
title("Estimated Mean Value and 95% Estimation Interval \n for Y with a new X")
```

```{r}
# Plotting with Predicted Values
fit1.1_pred2 = predict(fit1.1, newdata = X_plot, interval = "prediction")
plot(Balance~Rating, data= train2, pch = 16)
abline(fit1.1, col=4, lwd=2)
lines(X_plot$Rating,fit1.1_pred2[,2],col=6, lwd=2)
lines(X_plot$Rating,fit1.1_pred2[,3],col=6, lwd=2)
title("Predicted Value and 95% prediction Interval \n for Y with a new X")
```

#### "Limit" variables
```{r}
# Building the fitting line of "Rating" and "Balance"
fit1.2 <- lm(Balance~Limit, data= train2)
```

```{r}
summary(fit1.2)
```

```{r}
# ANOVA analysis
anova(fit1.2)
```

```{r}
# The estimated values of the coefficients
coefficients(fit1.2)
```

```{r}
# The confience interval
confint(fit1.2,level = 0.95)
```

```{r}
# Plotting with Estimated Values
plot(Balance~Limit, data = train2, pch = 16)
abline(fit1.2,col=4,lwd=2)
X_plot <- data.frame(Limit=seq(854,13915,by=1))
fit1.2_pred <- predict(fit1.2, newdata = X_plot, interval = "confidence")
lines(X_plot$Limit,fit1.2_pred[,2],col=5, lwd=2)
lines(X_plot$Limit,fit1.2_pred[,3],col=5, lwd=2)
title("Estimated Mean Value and 95% Estimation Interval \n for Y with a new X")
```

```{r}
# Plotting with Predicted Values
fit1.2_pred2 = predict(fit1.2, newdata = X_plot, interval = "prediction")
plot(Balance~Limit, data= train2, pch = 16)
abline(fit1.2, col=4, lwd=2)
lines(X_plot$Limit,fit1.2_pred2[,2],col=6, lwd=2)
lines(X_plot$Limit,fit1.2_pred2[,3],col=6, lwd=2)
title("Predicted Value and 95% prediction Interval \n for Y with a new X")
```
Both of the results are silimar, there is probably the strong relation between these two exploratory variables.

### Multiple regression
#### Use Backward Selection to justify the model.
```{r}
# Put the all variables to fitting model
fit2 <- lm(Balance~., data = train2)
summary(fit2)
```

```{r}
# Removed unrelated variables (high p-value) to adjust the fitting model
fit3 <- step(fit2)
summary(fit3)
```

```{r}
# Compare with these two models
anova(fit2,fit3)
```
* It is not significant independent between two models.
#### Coeff. of all-variables model and adjusted model
```{r}
# Coeff. of all-variables model
coefficients(fit2)
```

```{r}
# Coeff. of adjusted model
coefficients(fit3)
```

### Explaination of fitted model
* The value should be a little different, because the process of spliting data is random while the Rmd file running.

* Multiple R-squared and adjusted R-squared in **all-variables** model is 0.9551 and 0.9535 respectively; moreover, multiple R-squared and adjusted R-squared in **adjusted** model is 0.9546 and 0.9537 respectively. The all-variables model has had the high value of the coefficient of determination, so the adjusted R-squared in ajusted model just rised a little.

* The residual standard error in adjusted model is a little smaller than the one in all-variables model.

* The removed variables may have the strong interactions with the residual variables.
* In the adjusted model, the Pr of "Limit" is much smaller than "Rating".

### Testing data to predict balance
#### Simple Linear Model
* In the adjusted model, the Pr of "Limit" is much smaller than "Rating".
* Therefore, I choose "Limit" variable to predict "Balance" variable.
```{r}
# Simple Linear model
coeffS <- coefficients(fit1.2)
y_pred <- coeffS[1] + coeffS[2]*test2$Limit
plot(y_pred~test2$Balance, xlab="Predicted Balance",ylab = "Balance")
```

#### Multiple Model
```{r}
# Adjusted Model
coeffS <- coefficients(fit3)
y_pred <- coeffS[1] + coeffS[2]*test2$Income + coeffS[3]*test2$Limit + coeffS[4]*test2$Rating + coeffS[5]*test2$Cards + coeffS[6]*test2$Age + coeffS[7]*test2$StudentYes
plot(y_pred~test2$Balance, xlab="Predicted Balance",ylab = "Balance")
```

* The multiple model is better than the simple model in this case.
* The result is the validation of what teaching on the class.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
